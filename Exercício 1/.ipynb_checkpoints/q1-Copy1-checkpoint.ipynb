{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "#import statistics as stats\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "#from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from deslib.static import Oracle\n",
    "from rlo import * #rlo.py - Random Linear Oracle implementation based on Kuncheva's book. \n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's build a function to convert KEEL data to a regular CSV (remove annotations before data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keel2csv(file):\n",
    "    ''' Reads a KEEL .dat file, converts it into a regular CSV data file \n",
    "    that contains a header line. The output .csv file is written to the same \n",
    "    dir as the original .dat file. This function also returns a dict \n",
    "    {'numeric':[], 'nominal':[]} containg two lists, one for the numeric \n",
    "    attributes and the other for the nominal atributes.'''\n",
    "    filename = file.name\n",
    "    # Let's read the attribute types (useful for preprocessing) and also the \n",
    "    # column names from the @annotations, inclunding the target (class) column:\n",
    "    has_inputs = has_outputs = False\n",
    "    numeric_atts = []\n",
    "    nominal_atts = []\n",
    "    for line in file:\n",
    "        if '@attribute' in line:\n",
    "            if (' real' in line) or (' integer' in line):\n",
    "                numeric_atts.append(line.split(' ')[1])\n",
    "            elif '{' in line:\n",
    "                nominal_atts.append(line.split(' ')[1])\n",
    "        if line.startswith('@inputs'):\n",
    "            att_names = line[8:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@input'):\n",
    "            att_names = line[7:-1].replace(' ', '')\n",
    "            has_inputs = True\n",
    "        elif line.startswith('@outputs') or line.startswith('@output'):\n",
    "            class_name = line[9:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "        elif line.startswith('@output'):\n",
    "            class_name = line[8:-1]\n",
    "            has_outputs = True\n",
    "            break\n",
    "    if (not has_inputs) or (not has_outputs):\n",
    "        print('File ', filename, 'missing annotations?' )\n",
    "\n",
    "    columns = att_names + ',' + class_name\n",
    "\n",
    "    #Then, lets remove the annotations and save the column names and data into a csv file:\n",
    "    lines = file.readlines() \n",
    "    file.close()\n",
    "    new_file = open(filename[:-4]+'.csv','w')\n",
    "    new_file.write(columns+'\\n')\n",
    "    for line in lines:\n",
    "        if not line.startswith('@'):\n",
    "            new_file.write(line)\n",
    "    new_file.close()    \n",
    "    return {'numeric':numeric_atts, 'nominal':nominal_atts}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we need to run through the files and execute the keel2csv function for each KEEL dat file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = ['glass1', 'wisconsin', 'pima', 'ecoli2', 'vowel0']\n",
    "rootdir = '/Users/lucasamorim/Downloads/KEEL_imb_classification_data_exercicio1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting KEEL .dat files to CSV:\n",
    "att_types = {} #This dictionary will have each dataset name as key and will hold the attribute types.\n",
    "for name in ds_names:\n",
    "    for fold in range(1,6):\n",
    "        full_path = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tra.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        att_types[name] = keel2csv(f)\n",
    "        f.close()\n",
    "        full_path = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tst.dat' \n",
    "        f = open(full_path, 'r')\n",
    "        keel2csv(f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok, now that we finally have all the data in CSV format, lets load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will create a dict structure such that I can access train fold 1 from \n",
    "# dataset wisconsin as datasets['wisconsin']['train'][0]\n",
    "\n",
    "datasets = {}\n",
    "for name in ds_names:\n",
    "    datasets[name] = {}\n",
    "    datasets[name]['train'] = []\n",
    "    datasets[name]['test'] = []\n",
    "    for fold in range(1,6):\n",
    "        csv_filename = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tra.csv'\n",
    "        df_train = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        csv_filename = rootdir+'/'+name+'-5-fold/'+name+'-5-'+str(fold)+'tst.csv'\n",
    "        df_test = pd.read_csv(csv_filename, encoding='utf8', engine='python', sep=',', \n",
    "                     header=0, error_bad_lines=False)\n",
    "        datasets[name]['train'].append(df_train)\n",
    "        datasets[name]['test'].append(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Plas</th>\n",
       "      <th>Pres</th>\n",
       "      <th>Skin</th>\n",
       "      <th>Insu</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Pedi</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.520</td>\n",
       "      <td>67.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>37.1</td>\n",
       "      <td>0.153</td>\n",
       "      <td>43.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>23.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.268</td>\n",
       "      <td>31.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.727</td>\n",
       "      <td>41.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>4.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.317</td>\n",
       "      <td>34.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.209</td>\n",
       "      <td>37.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.334</td>\n",
       "      <td>25.0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.328</td>\n",
       "      <td>38.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preg   Plas  Pres  Skin   Insu  Mass   Pedi   Age      Class\n",
       "0     4.0  146.0  78.0   0.0    0.0  38.5  0.520  67.0   positive\n",
       "1    15.0  136.0  70.0  32.0  110.0  37.1  0.153  43.0   positive\n",
       "2     3.0  107.0  62.0  13.0   48.0  22.9  0.678  23.0   positive\n",
       "3     3.0  169.0  74.0  19.0  125.0  29.9  0.268  31.0   positive\n",
       "4     6.0    0.0  68.0  41.0    0.0  39.0  0.727  41.0   positive\n",
       "..    ...    ...   ...   ...    ...   ...    ...   ...        ...\n",
       "610   5.0  117.0  92.0   0.0    0.0  34.1  0.337  38.0   negative\n",
       "611   4.0   83.0  86.0  19.0    0.0  29.3  0.317  34.0   negative\n",
       "612   7.0  119.0   0.0   0.0    0.0  25.2  0.209  37.0   negative\n",
       "613   1.0   95.0  66.0  13.0   38.0  19.6  0.334  25.0   negative\n",
       "614   1.0  181.0  64.0  30.0  180.0  34.1  0.328  38.0   positive\n",
       "\n",
       "[615 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['pima']['train'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning (stripping) strings within dataframe and also changing class labels to 1 and 0.\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            df = datasets[name][s][fold]\n",
    "            df_obj = df.select_dtypes(['object'])\n",
    "            df[df_obj.columns] = df_obj.apply(lambda x: x.str.strip())\n",
    "            df['Class'] = df['Class'].replace(['positive', 'negative'],[1,0])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "\n",
    "Here we must apply this encoding method to the nominal attributes in order to allow them to be managed by the classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            for att in att_types[name]['nominal'][:-1]: #For each nominal attribute, except the target one (last one)\n",
    "                att_encoded = pd.get_dummies(datasets[name][s][fold][att], prefix = att)\n",
    "                datasets[name][s][fold] = datasets[name][s][fold].drop([att], axis = 1)\n",
    "                datasets[name][s][fold] = pd.concat([att_encoded, datasets[name][s][fold]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Applying the Standard Scaler to the numeric attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            datasets[name][s][fold][att_types[name]['numeric']] = ss.fit_transform(datasets[name][s][fold][att_types[name]['numeric']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "\n",
    "Applying a Simple Imputer to the numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "for name in ds_names:\n",
    "    for s in ['train', 'test']:\n",
    "        for fold in range(5):\n",
    "            datasets[name][s][fold][att_types[name]['numeric']] = imp_mean.fit_transform(datasets[name][s][fold][att_types[name]['numeric']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulding and running the ensembles of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Linear Oracles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built RLO\n",
      "Entrei no for, i =  0\n",
      "rp =  [457 290]\n",
      "rp[0] =  457\n",
      "rp[1] =  290\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'(array([ True,  True,  True,  True,  True, False, False, False,  True,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False,  True, False,\n        True,  True, False,  True,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n       False,  True,  True, False,  True, False, False,  True,  True,\n       False,  True,  True,  True,  True,  True,  True, False, False,\n        True,  True, False, False, False,  True,  True,  True,  True,\n       False, False,  True, False,  True,  True,  True,  True, False,\n        True,  True, False,  True,  True, False,  True, False,  True,\n       False,  True,  True,  True,  True,  True,  True, False,  True,\n       False,  True, False,  True, False,  True,  True, False,  True,\n       False,  True,  True, False,  True, False, False, False,  True,\n        True, False,  True,  True,  True, False, False, False,  True,\n       False,  True,  True,  True, False,  True,  True,  True,  True,\n        True, False, False,  True,  True, False,  True,  True,  True,\n        True,  True, False, False,  True, False,  True,  True,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False,  True,  True, False,  True,  True,  True,  True,\n        True, False,  True,  True,  True,  True, False, False,  True,\n       False, False,  True, False, False, False,  True,  True, False,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n       False, False,  True, False, False,  True, False,  True, False,\n        True,  True, False, False,  True,  True,  True,  True,  True,\n        True, False, False,  True,  True, False, False, False,  True,\n        True, False, False, False, False,  True,  True, False,  True,\n        True,  True, False,  True, False,  True,  True, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n       False,  True, False,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True, False,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False,  True, False, False,  True, False,  True,  True,\n        True,  True, False,  True,  True,  True,  True,  True,  True,\n        True, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True, False,  True,  True,  True, False, False,  True,  True,\n        True,  True,  True, False, False,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True, False, False, False,\n        True,  True,  True,  True,  True,  True, False,  True, False,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True, False,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True, False,  True,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True,  True, False, False,  True,\n       False, False,  True, False,  True,  True,  True,  True,  True,\n        True, False,  True, False,  True, False, False,  True,  True,\n       False, False, False, False,  True,  True,  True, False,  True,\n       False,  True,  True,  True,  True,  True,  True, False,  True,\n        True, False,  True, False, False,  True,  True,  True, False,\n        True,  True,  True,  True,  True,  True, False, False,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n       False, False,  True,  True, False,  True]), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-150cdc1a3e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_att\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Doutorado/CIn/2020.2/IN1105 - Tópicos MCS/Exercício 1/rlo.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mclassificador_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mclassificador_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'D_{i}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassificador_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'D_{i}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassificador_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Got here 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2644\u001b[0m                 )\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(array([ True,  True,  True,  True,  True, False, False, False,  True,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False,  True, False,\n        True,  True, False,  True,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n       False,  True,  True, False,  True, False, False,  True,  True,\n       False,  True,  True,  True,  True,  True,  True, False, False,\n        True,  True, False, False, False,  True,  True,  True,  True,\n       False, False,  True, False,  True,  True,  True,  True, False,\n        True,  True, False,  True,  True, False,  True, False,  True,\n       False,  True,  True,  True,  True,  True,  True, False,  True,\n       False,  True, False,  True, False,  True,  True, False,  True,\n       False,  True,  True, False,  True, False, False, False,  True,\n        True, False,  True,  True,  True, False, False, False,  True,\n       False,  True,  True,  True, False,  True,  True,  True,  True,\n        True, False, False,  True,  True, False,  True,  True,  True,\n        True,  True, False, False,  True, False,  True,  True,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False,  True,  True, False,  True,  True,  True,  True,\n        True, False,  True,  True,  True,  True, False, False,  True,\n       False, False,  True, False, False, False,  True,  True, False,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n       False, False,  True, False, False,  True, False,  True, False,\n        True,  True, False, False,  True,  True,  True,  True,  True,\n        True, False, False,  True,  True, False, False, False,  True,\n        True, False, False, False, False,  True,  True, False,  True,\n        True,  True, False,  True, False,  True,  True, False,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n       False,  True, False,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True, False,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True, False,  True, False, False,  True, False,  True,  True,\n        True,  True, False,  True,  True,  True,  True,  True,  True,\n        True, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True, False,  True,  True,  True, False, False,  True,  True,\n        True,  True,  True, False, False,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True, False, False, False,\n        True,  True,  True,  True,  True,  True, False,  True, False,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True, False,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True, False,  True,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True,  True, False, False,  True,\n       False, False,  True, False,  True,  True,  True,  True,  True,\n        True, False,  True, False,  True, False, False,  True,  True,\n       False, False, False, False,  True,  True,  True, False,  True,\n       False,  True,  True,  True,  True,  True,  True, False,  True,\n        True, False,  True, False, False,  True,  True,  True, False,\n        True,  True,  True,  True,  True,  True, False, False,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n       False, False,  True,  True, False,  True]), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "#Test RLO\n",
    "\n",
    "base_model = Perceptron(random_state=0)\n",
    "meta_model = RLO(base_estimator=base_model) \n",
    "\n",
    "ds_train = datasets['wisconsin']['train'][0]\n",
    "target_att = ds_train.columns.tolist()[-1]\n",
    "X_train = ds_train.drop(labels=target_att, axis = 1) \n",
    "y_train = ds_train[target_att]\n",
    "\n",
    "meta_model.fit(X_train, y_train)\n",
    "print('oi')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "rp = np.random.choice(N, 2)\n",
    "rp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
